{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Cost Function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Regression Cost Function in machine learning is a function that computes the error of a regression model in predicting the continuous output value for a given input. The cost function quantifies the difference between the predicted and actual continuous values in the dataset.\n",
    "\n",
    "The goal of a regression model is to minimize this cost function, which would mean that the model's predictions closely match the actual values. The cost function is used by the optimization algorithm (like Gradient Descent) to adjust the parameters of the regression model.\n",
    "\n",
    "In essence, the Regression Cost Function provides a measure of how well the regression model is performing. It's a crucial part of training a regression model, as it guides the learning algorithm to the best set of parameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Mean Error (ME)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "L(y, f(x)) = 0.5 * (y - f(x))^2                      for |y - f(x)| <= δ\n",
    "L(y, f(x)) = δ * |y - f(x)| - 0.5 * δ^2              for |y - f(x)| > δ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "- `y` is the actual value.\n",
    "- `f(x)` is the predicted value.\n",
    "- `δ` is a hyperparameter that controls the point at which the loss function transitions from quadratic to linear. \n",
    "\n",
    "The Huber Loss has the property that it behaves like the Mean Squared Error (MSE) for small differences between actual and predicted values, but like the Mean Absolute Error (MAE) for large differences. The quadratic (MSE) portion makes the loss function differentiable at `y = f(x)`, which is important for optimization algorithms like gradient descent.\n",
    "\n",
    "The value of `δ` determines what is considered a \"small\" difference. This makes the Huber Loss more robust to outliers than the MSE, as it treats them as linear to limit the impact of large residuals on the overall estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Error (ME) is a measure of the average error in the predictions made by a model. It's calculated as the average of the difference between the predicted values and the actual values. \n",
    "\n",
    "Mathematically, it is calculated as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "ME = (1/n) * Σ(y_i - ŷ_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "- `n` is the total number of data points or instances.\n",
    "- `y_i` is the actual value of an instance.\n",
    "- `ŷ_i` is the predicted value of an instance.\n",
    "- `Σ` is the sum over all instances.\n",
    "- `(y_i - ŷ_i)` is the difference between the actual and predicted value.\n",
    "\n",
    "The ME can be positive or negative. A positive value indicates that the model's predictions are, on average, higher than the actual values, while a negative value indicates that the model's predictions are, on average, lower than the actual values.\n",
    "\n",
    "However, one of the main limitations of the ME is that it can be misleading because positive and negative errors can cancel each other out. This is why other metrics like Mean Absolute Error (MAE) or Mean Squared Error (MSE) are often preferred, as they consider the magnitude of the errors regardless of their direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mean Absolute Error (MAE)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE) is a popular metric used in regression problems. It measures the average magnitude of errors in a set of predictions, without considering their direction. It's the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.\n",
    "\n",
    "Mathematically, it is calculated as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "MAE = (1/n) * Σ|y_i - ŷ_i|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "- `n` is the total number of data points or instances.\n",
    "- `y_i` is the actual value of an instance.\n",
    "- `ŷ_i` is the predicted value of an instance.\n",
    "- `Σ` is the sum over all instances.\n",
    "- `|y_i - ŷ_i|` is the absolute difference between the actual and predicted value.\n",
    "\n",
    "The MAE is a linear score, which means all the individual differences are weighted equally in the average. For example, the difference between 10 and 0 will be twice the difference between 5 and 0. \n",
    "\n",
    "One of the main advantages of MAE is that it does not penalize large errors as harshly as metrics like Mean Squared Error (MSE). This makes it less sensitive to outliers in the data. However, because it uses absolute values rather than squares, it may not adequately reflect the impact of large errors in some applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mean Squared Error (MSE)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE) is a commonly used regression loss function that measures the average of the squares of the errors. In other words, it's the average squared difference between the estimated values and the actual value.\n",
    "\n",
    "Mathematically, it is calculated as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "MSE = (1/n) * Σ(y_i - ŷ_i)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "- `n` is the total number of data points or instances.\n",
    "- `y_i` is the actual value of an instance.\n",
    "- `ŷ_i` is the predicted value of an instance.\n",
    "- `Σ` is the sum over all instances.\n",
    "- `(y_i - ŷ_i)^2` is the squared difference between the actual and predicted value.\n",
    "\n",
    "The MSE is always non-negative, and a value of 0 indicates a perfect fit to the data. In general, a lower MSE means a better fit to the data.\n",
    "\n",
    "One of the main advantages of MSE is that it penalizes larger errors more than smaller ones, due to the squared term. This can be useful in many practical cases where larger errors are particularly undesirable.\n",
    "\n",
    "However, one of the downsides of MSE is that it is sensitive to outliers, since the squaring of the error term can lead to significant increases in the error for outliers. This means that a model trained using MSE as a loss function may perform poorly if there are outliers in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Huber Loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber Loss, also known as Smooth Mean Absolute Error, is a loss function used in robust regression, that is less sensitive to outliers in data than the squared error loss.\n",
    "\n",
    "The Huber Loss function is defined as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "L(y, f(x)) = 0.5 * (y - f(x))^2                      for |y - f(x)| <= δ\n",
    "L(y, f(x)) = δ * |y - f(x)| - 0.5 * δ^2              for |y - f(x)| > δ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "- `y` is the actual value.\n",
    "- `f(x)` is the predicted value.\n",
    "- `δ` is a hyperparameter that controls the point at which the loss function transitions from quadratic to linear. \n",
    "\n",
    "The Huber Loss has the property that it behaves like the Mean Squared Error (MSE) for small differences between actual and predicted values, but like the Mean Absolute Error (MAE) for large differences. The quadratic (MSE) portion makes the loss function differentiable at `y = f(x)`, which is important for optimization algorithms like gradient descent.\n",
    "\n",
    "The value of `δ` determines what is considered a \"small\" difference. This makes the Huber Loss more robust to outliers than the MSE, as it treats them as linear to limit the impact of large residuals on the overall estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple dataset with 5 instances. The actual values (`y`) are [3, -0.5, 2, 7, 4.2] and the predicted values (`ŷ`) are [2.5, 0.0, 2.1, 7.8, 5.3].\n",
    "\n",
    "**1. Mean Error (ME):**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "ME = (1/n) * Σ(y_i - ŷ_i)\n",
    "   = (1/5) * [(3 - 2.5) + (-0.5 - 0.0) + (2 - 2.1) + (7 - 7.8) + (4.2 - 5.3)]\n",
    "   = (1/5) * [0.5 - 0.5 - 0.1 - 0.8 - 1.1]\n",
    "   = -0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**2. Mean Absolute Error (MAE):**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "MAE = (1/n) * Σ|y_i - ŷ_i|\n",
    "    = (1/5) * [|3 - 2.5| + |-0.5 - 0.0| + |2 - 2.1| + |7 - 7.8| + |4.2 - 5.3|]\n",
    "    = (1/5) * [0.5 + 0.5 + 0.1 + 0.8 + 1.1]\n",
    "    = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**3. Mean Squared Error (MSE):**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "MSE = (1/n) * Σ(y_i - ŷ_i)^2\n",
    "    = (1/5) * [(3 - 2.5)^2 + (-0.5 - 0.0)^2 + (2 - 2.1)^2 + (7 - 7.8)^2 + (4.2 - 5.3)^2]\n",
    "    = (1/5) * [0.25 + 0.25 + 0.01 + 0.64 + 1.21]\n",
    "    = 0.47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**4. Huber Loss:**\n",
    "\n",
    "Let's assume `δ` = 1 for this calculation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "L(y, f(x)) = 0.5 * (y - f(x))^2                      for |y - f(x)| <= δ\n",
    "L(y, f(x)) = δ * |y - f(x)| - 0.5 * δ^2              for |y - f(x)| > δ\n",
    "\n",
    "Huber Loss = (1/n) * Σ L(y_i, ŷ_i)\n",
    "           = (1/5) * [L(3, 2.5) + L(-0.5, 0.0) + L(2, 2.1) + L(7, 7.8) + L(4.2, 5.3)]\n",
    "           = (1/5) * [0.5*(3 - 2.5)^2 + 0.5*(-0.5 - 0.0)^2 + 0.5*(2 - 2.1)^2 + (1*|7 - 7.8| - 0.5*1^2) + (1*|4.2 - 5.3| - 0.5*1^2)]\n",
    "           = (1/5) * [0.125 + 0.125 + 0.005 + 0.3 + 0.6]\n",
    "           = 0.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "These are the calculated values for the different regression loss functions for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Thank You!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
